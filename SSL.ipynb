{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/aris/.conda/envs/nnUNet_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Self-Supervised Learning with DINO on CIFAR-10 using ResNet50\n",
    "# This notebook includes local and global crops, centering and sharpening,\n",
    "# and evaluates the model under different training conditions.\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.resnet import ResNet\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Transformations for Local and Global Crops\n",
    "class DINOTransform(object):\n",
    "    def __init__(self, global_crop_scale=(0.4, 1.0), local_crop_scale=(0.05, 0.4), local_crops_number=4, image_size=32):\n",
    "        self.global_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_size, scale=global_crop_scale),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262)),\n",
    "        ])\n",
    "        \n",
    "        self.local_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_size, scale=local_crop_scale),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262)),\n",
    "        ])\n",
    "        self.local_crops_number = local_crops_number\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Two global crops for teacher and student, several local crops for student\n",
    "        crops = [self.global_transform(x) for _ in range(2)]  # 2 global crops\n",
    "        crops.extend([self.local_transform(x) for _ in range(self.local_crops_number)])  # 4 local crops is default\n",
    "\n",
    "        return crops\n",
    "\n",
    "sl_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(0.4, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess CIFAR-10 dataset\n",
    "def load_data(batch_size):\n",
    "    ssl_transform = DINOTransform()\n",
    "    ssl_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=ssl_transform)\n",
    "    sl_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=sl_transform)\n",
    "    val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transform)\n",
    "\n",
    "    ssl_train_loader = DataLoader(ssl_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8, drop_last=True)\n",
    "    sl_train_loader = DataLoader(sl_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True, num_workers=8)\n",
    "    return ssl_train_loader, sl_train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DINO framework with ResNet50\n",
    "class DINO(nn.Module):\n",
    "    def __init__(self, student: nn.Module,\n",
    "                    teacher: nn.Module,\n",
    "                    num_classes: int,\n",
    "                    device: torch.device,\n",
    "                    temperature_student=0.07,\n",
    "                    temperature_teacher=0.04,\n",
    "                    learning_rate=0.001,\n",
    "                    momentum=0.9,\n",
    "                    center_momentum=0.9,\n",
    "                    local_crops_number=4):\n",
    "        super(DINO, self).__init__()\n",
    "        self.device = device\n",
    "        self.student = student.to(device)\n",
    "        self.teacher = teacher.to(device)\n",
    "        self.teacher.load_state_dict(self.student.state_dict())\n",
    "        self.optimizer = optim.AdamW(self.student.parameters(), lr=learning_rate)\n",
    "        self.temperature_student = temperature_student\n",
    "        self.temperature_teacher = temperature_teacher\n",
    "        self.center_momentum = center_momentum\n",
    "        self.momentum = momentum\n",
    "        self.register_buffer('center', torch.zeros(1, num_classes))\n",
    "        self.local_crops_number=local_crops_number\n",
    "        \n",
    "        teacher.eval()\n",
    "        for param in self.teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    def H(self, teacher_outputs, student_outputs):\n",
    "        \"\"\"\n",
    "        Custom cross-entropy for soft labels, applied with centering and sharpening.\n",
    "        \"\"\"\n",
    "\n",
    "        #print(\"Student_outputs shape:\", student_outputs.shape)\n",
    "        #print(\"Teacher outputs shape: \", teacher_outputs.shape)\n",
    "        #print(\"student_outputs device: \", student_outputs.get_device())\n",
    "        student_probs = nn.functional.log_softmax(student_outputs / self.temperature_student, dim=1)\n",
    "\n",
    "        teacher_outputs = teacher_outputs.detach()\n",
    "        #print(\"teacher_outputs device: \", teacher_outputs.get_device())\n",
    "        centered_output = (teacher_outputs - self.center)\n",
    "        teacher_probs = nn.functional.softmax(centered_output / self.temperature_teacher, dim=1)\n",
    "\n",
    "        #print(\"Student_probs shape: \", student_probs.shape)\n",
    "        #print(\"Teacher probs shape: \", teacher_probs.shape)\n",
    "\n",
    "        \n",
    "        loss = - (teacher_probs * student_probs).sum(dim=1).mean()\n",
    "\n",
    "        #print(len(losses))\n",
    "        #print(\"losses stack shape\", torch.stack(losses).shape)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def train_step(self, crops: tuple[list, list]):\n",
    "        \"\"\"\n",
    "        Perform a single training step with DINO.\n",
    "        Args:\n",
    "            crops (tuple of list of Tensor): List containing augmented two augmented views of the same image.\n",
    "        \"\"\"\n",
    "        # Forward pass through the student model on both global and local crops\n",
    "        student_outputs = torch.stack([self.student(crop.to(self.device)) for crop in crops])\n",
    "        #student_outputs = self.student(crops)\n",
    "        \n",
    "        # Forward pass through the teacher model on global crops only\n",
    "        with torch.no_grad():\n",
    "            #print(crops[:2].shape)\n",
    "            teacher_crops = crops[:2] # We use only the two global crops\n",
    "            teacher_outputs = torch.stack([self.teacher(crop.to(self.device)) for crop in teacher_crops])\n",
    "        \n",
    "        # Compute DINO loss using soft cross-entropy with centering and sharpening for every pair t and s\n",
    "        losses = []\n",
    "        for t in teacher_outputs:\n",
    "            for s in student_outputs:\n",
    "                dino_loss = self.H(t, s)\n",
    "                losses.append(dino_loss)\n",
    "        \n",
    "        #print(\"loss shape: \", torch.stack(losses).shape)\n",
    "\n",
    "        loss = torch.stack(losses).mean()\n",
    "        #print(\"Loss: \", loss.item())\n",
    "        \n",
    "        #loss /= len(student_outputs)  # Normalize by the number of student outputs\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update teacher model after each batch\n",
    "        for param_student, param_teacher in zip(self.student.parameters(), self.teacher.parameters()):\n",
    "            param_teacher.data = self.momentum * param_teacher.data + (1 - self.momentum) * param_student.data\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.center = self.center_momentum * self.center + (1 - self.center_momentum)*teacher_outputs.mean(dim=0)\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def ssl_train(dino, train_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (images, _) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            #print(\"data shape: \", data.shape)\n",
    "            #print(\"images shape: \", np.shape(images))\n",
    "            loss = dino.train_step(images)\n",
    "            #print(\"batch loss: \", batch_loss)\n",
    "            total_loss += loss\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(student, val_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the student model on the validation set.\n",
    "    \"\"\"\n",
    "    student.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = student(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "    student.train()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "ssl_epochs = 5\n",
    "sl_epochs = 20\n",
    "learning_rate = 0.001\n",
    "temperature_teacher = 0.04\n",
    "temperature_student = 0.07\n",
    "num_classes = 10\n",
    "local_crops_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Model Initialization with ResNet50\n",
    "student_model = resnet50(num_classes=num_classes)\n",
    "teacher_model = resnet50(num_classes=num_classes)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "supervised_only_model = copy.deepcopy(student_model).to(device)\n",
    "\n",
    "# Instantiate DINO framework\n",
    "dino = DINO(student=student_model, teacher=teacher_model, device=device, num_classes=num_classes,\n",
    "            temperature_student=temperature_student, temperature_teacher=temperature_teacher, \n",
    "            learning_rate=learning_rate, local_crops_number=local_crops_number)\n",
    "\n",
    "dino.to(device)\n",
    "\n",
    "# Load data\n",
    "ssl_train_loader, sl_train_loader, val_loader = load_data(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with random weights (no training):\n",
      "Validation Accuracy: 11.03%\n"
     ]
    }
   ],
   "source": [
    "# 1. Evaluate ResNet50 without any training (random weights), should be around 10%\n",
    "print(\"Evaluation with random weights (no training):\")\n",
    "evaluate(dino.student, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with self-supervised learning (DINO):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [01:14<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 9.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [01:14<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 3.9559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [01:14<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 1.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [01:14<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 1.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [01:11<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 1.6333\n",
      "\n",
      "Evaluation after self-supervised learning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# 2. Train with only self-supervised learning, should be roughly the same as without any supervised training\n",
    "print(\"\\nTraining with self-supervised learning (DINO):\")\n",
    "ssl_train(dino, ssl_train_loader, ssl_epochs)\n",
    "print(\"\\nEvaluation after self-supervised learning:\")\n",
    "evaluate(dino.student, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Supervised training function (on top of self-supervised pre-trained student model)\n",
    "def supervised_train(model, train_loader, epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "    print(\"Supervised training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet50 model with supervised learning only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:09<00:00, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 1.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 1.6971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 1.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 1.4890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 1.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 1.4210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 1.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:09<00:00, 20.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 1.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 1.8314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 1.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 1.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 1.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 1.1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 1.1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 1.4402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 1.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 1.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 1.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 1.0537\n",
      "Supervised training complete.\n",
      "\n",
      "Evaluation after supervised training only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 64.41%\n"
     ]
    }
   ],
   "source": [
    "# 4. Train supervised-only ResNet50 model for comparison\n",
    "print(\"\\nTraining ResNet50 model with supervised learning only:\")\n",
    "supervised_train(supervised_only_model, sl_train_loader, sl_epochs)\n",
    "print(\"\\nEvaluation after supervised training only:\")\n",
    "evaluate(supervised_only_model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning (supervised) after self-supervised pre-training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:09<00:00, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 1.5922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 1.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 1.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 2.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 1.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 1.5285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:09<00:00, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 1.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 1.4558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 1.3326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 1.4449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 1.4216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 1.2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 1.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 1.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 1.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 195/195 [00:09<00:00, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.9074\n",
      "Supervised training complete.\n",
      "\n",
      "Evaluation after self-supervised pre-training + supervised fine-tuning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 69.15%\n"
     ]
    }
   ],
   "source": [
    "# 5. Fine-tune (supervised) after self-supervised pre-training, should be slighlty better than only supervised\n",
    "print(\"\\nFine-tuning (supervised) after self-supervised pre-training:\")\n",
    "supervised_train(dino.student, sl_train_loader, sl_epochs)\n",
    "print(\"\\nEvaluation after self-supervised pre-training + supervised fine-tuning:\")\n",
    "evaluate(dino.student, val_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
